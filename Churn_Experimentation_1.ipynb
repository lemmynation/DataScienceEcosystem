{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lemmynation/DataScienceEcosystem/blob/main/Churn_Experimentation_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8-p556gt8fT"
      },
      "source": [
        "# **Importing Files**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvSs66wGrvjF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "Pxkpt6yusS_5",
        "outputId": "7bf4ada5-1153-4f9e-e4dc-d93d48fe094f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-d7227f9cdd9b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m  \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import  drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJYf2_WGs5yc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "6499beca-2dcd-4cff-e30e-7b146bbadadf"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Data Science Masters/2023-2024 Second Sem/Machine Learning/churn.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-bc6b15b60db4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/Data Science Masters/2023-2024 Second Sem/Machine Learning/churn.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Data Science Masters/2023-2024 Second Sem/Machine Learning/churn.csv'"
          ]
        }
      ],
      "source": [
        "path = '/content/drive/MyDrive/Data Science Masters/2023-2024 Second Sem/Machine Learning/churn.csv'\n",
        "df = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEp-ZwqZtyY6"
      },
      "source": [
        "# **Exploratory Data Analysis (EDA)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "JGc5MLeEtqah",
        "outputId": "0d7189c8-53e1-45d9-f9a9-cadd0e906647"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-4a676c3d8c05>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "g7FOB8Cjtvvy",
        "outputId": "0321fc0f-7267-43eb-a527-3d67f9637f28"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-b666bf274d0a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8Ge9fxVuMSY"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82MpJUe2vdKe"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogJal7PruQoo"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6F7h0xUTujUw"
      },
      "outputs": [],
      "source": [
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5c9Z2U6ourlm"
      },
      "outputs": [],
      "source": [
        "df.isnull().any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYerjRzwzYj5"
      },
      "outputs": [],
      "source": [
        "def histogrammer(column_str, median_text=True, **kwargs):    # **kwargs = any keyword arguments\n",
        "                                                             # from the sns.histplot() function\n",
        "    median=round(df[column_str].median(), 1)\n",
        "    plt.figure(figsize=(5,3))\n",
        "    ax = sns.histplot(x=df[column_str], **kwargs)            # Plot the histogram\n",
        "    plt.axvline(median, color='red', linestyle='--')         # Plot the median line\n",
        "    if median_text==True:                                    # Add median text unless set to False\n",
        "        ax.text(0.25, 0.85, f'median={median}', color='red',\n",
        "            ha='left', va='top', transform=ax.transAxes)\n",
        "    else:\n",
        "        print('Median:', median)\n",
        "    plt.title(f'{column_str} histogram');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tmgRMp3wQLZ"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(5,1))\n",
        "sns.boxplot(x=df['income'], fliersize=1)\n",
        "plt.title('income box plot');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iueQm19syNOV"
      },
      "source": [
        "It highlights the concentration of incomes around **60,000 to 100,000**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oX3L1DiGw04j"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(5,3))\n",
        "sns.histplot(x=df['income'])\n",
        "median = df['income'].median()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eE0j4KVyrab"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQzlBqRlzPiI"
      },
      "outputs": [],
      "source": [
        "histogrammer('income')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9oTiKw_y1_1"
      },
      "source": [
        " Revealing a higher count of people with incomes in the lower range. This disparity provides insights into income inequality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fp0jADAUw-oJ"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(5,1))\n",
        "sns.boxplot(x=df['overage'], fliersize=1)\n",
        "plt.title('overage box plot')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22zWDH6czBDM"
      },
      "outputs": [],
      "source": [
        "histogrammer('overage')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLPUy8ex0Q8-"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(5,1))\n",
        "sns.boxplot(x=df['leftover'])\n",
        "plt.title('left over box plot')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrkhcRaD0tm1"
      },
      "outputs": [],
      "source": [
        "histogrammer('leftover')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mcqta-I61YOB"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(5,1))\n",
        "sns.boxplot(x=df['house'])\n",
        "plt.title('house box plot')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIByOWWX1vFf"
      },
      "outputs": [],
      "source": [
        "histogrammer('house')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sG8-Bg3p13jZ"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(5,1))\n",
        "sns.boxplot(x=df['handset_price'])\n",
        "plt.title('handset_price box plot')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XishH3M2SIP"
      },
      "outputs": [],
      "source": [
        "histogrammer('handset_price')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8wVcoHW4s5d"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGWVhV572XWm"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(5,1))\n",
        "sns.boxplot(x=df['over_15mins_calls_per_month'])\n",
        "plt.title('Over 15mins calls per month box plot')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Isdy2CgJ20Tp"
      },
      "outputs": [],
      "source": [
        "histogrammer('over_15mins_calls_per_month')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HxkS6Bt32xw"
      },
      "source": [
        "The majority of call durations fall within the range of 0 to 5 minutes. This suggests that most calls are relatively short. The histogram exhibits a right-skewed distribution, with fewer calls having longer durations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qaPvWokn28qD"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(5,1))\n",
        "sns.boxplot(x=df['average_call_duration'])\n",
        "plt.title('Average Call Duration Box Plot')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQCTxHzF3ahK"
      },
      "outputs": [],
      "source": [
        "histogrammer('average_call_duration')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0wzOvCs3vq0"
      },
      "source": [
        "It reveals a skewed distribution, with most data points concentrated below an overage of 100."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4_-fo-63xXq"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(3,3))\n",
        "data=df['leave'].value_counts()\n",
        "plt.pie(data,\n",
        "        labels=[f'{data.index[0]}: {data.values[0]}',\n",
        "                f'{data.index[1]}: {data.values[1]}'],\n",
        "        autopct='%1.1f%%'\n",
        "        )\n",
        "plt.title('leave counts');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XR9xy9Xubm-C"
      },
      "source": [
        "**HANDLING OUTLIER**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4Ln3VQpZ5UV"
      },
      "outputs": [],
      "source": [
        "def outlier_imputer(column_name, percentile):\n",
        "    # Calculate threshold\n",
        "    threshold = df[column_name].quantile(percentile)\n",
        "    # Impute threshold for values > than threshold\n",
        "    df.loc[df[column_name] > threshold, column_name] = threshold\n",
        "\n",
        "    print('{:>25} | percentile: {} | threshold: {}'.format(column_name, percentile, threshold))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTuJGnUFbs08"
      },
      "outputs": [],
      "source": [
        "for column in ['income', 'overage', 'leftover',\n",
        "               'house', 'handset_price','over_15mins_calls_per_month','average_call_duration']:\n",
        "               outlier_imputer(column, 0.95)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRPPs6xAclT1"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2lQQVq2c9Z9"
      },
      "outputs": [],
      "source": [
        "df.corr()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrXvveoakkzm"
      },
      "source": [
        "**Duplicating Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuBI9p0ddn7Y"
      },
      "outputs": [],
      "source": [
        "df_copy = df.copy(deep = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTvw35cvdqos"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(df_copy[['income', 'overage', 'leftover','house','handset_price','over_15mins_calls_per_month','average_call_duration','leave']],\n",
        "             plot_kws={'alpha':0.4, 'size':5},\n",
        "             );"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTdFPk-8mzpn"
      },
      "source": [
        "# **DATA TRANSFORMATION INCLUDING SMOTE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw0dxGudlqmw"
      },
      "source": [
        "**Variable Encoding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxiy58tmjyTH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "d8ffe2a5-f1eb-4448-b6e3-b3e417fa66d2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_copy' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-117680220c3d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_copy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df_copy' is not defined"
          ]
        }
      ],
      "source": [
        "df_copy = pd.get_dummies(df_copy, drop_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "P7m3wbqJlBAx",
        "outputId": "e6a0735c-6cbb-409b-d1bd-9ff2ae88a580"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_copy' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-73439590a8bc>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df_copy' is not defined"
          ]
        }
      ],
      "source": [
        "df_copy.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3B9kdymLmFL7"
      },
      "source": [
        "**Dropping Columns**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drEANXOkmEZO"
      },
      "outputs": [],
      "source": [
        "df_copy = df_copy.drop(columns= 'Unnamed: 0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTyEVmnXmobW"
      },
      "outputs": [],
      "source": [
        "df_copy.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ox3r7pd0nAon"
      },
      "source": [
        "**Handling Imbalanced Datasets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GcHgiSZm-78"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "x = df_copy.drop(columns=['leave_STAY'])\n",
        "y = df_copy.leave_STAY # contains the target variable\n",
        "\n",
        "# The output will show the class distribution before applying SMOTE.\n",
        "print('before',Counter(y))\n",
        "\n",
        "smote = SMOTE()\n",
        "smotex, smotey = smote.fit_resample(x, y)\n",
        "\n",
        "print('after', Counter(smotey))\n",
        "\n",
        "plt.bar(Counter(y).keys(), Counter(y).values(), color='blue', label='Before Oversampling')\n",
        "plt.bar(Counter(smotey).keys(), Counter(smotey).values(), color='orange', label='After Oversampling')\n",
        "plt.legend()\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of Instances')\n",
        "plt.title('Class Distribution Before and After Oversampling')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0YbHUVLpak9"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import svm\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import * #ExtraTreesClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.tree import *\n",
        "\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "xtrain_, xtest_, ytrain_, ytest_ = train_test_split(smotex, smotey, test_size=0.2)"
      ],
      "metadata": {
        "id": "3fR8ukKDwAbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_score(names, models, _X_train, _y_train, _X_test, _y_test, index):\n",
        "    res = {' ':[index]} # key and a list containing the provided index as the value.\n",
        "    for n, model in enumerate(models):\n",
        "      trained = model.fit(_X_train, _y_train)\n",
        "      score = trained.score(_X_test, _y_test)\n",
        "      res[names[n]] = score\n",
        "    df = pd.DataFrame(res).set_index(' ') # Converts the res dictionary into a DataFrame using pandas (pd.DataFrame(res))\n",
        "    return df"
      ],
      "metadata": {
        "id": "PRKNqG_zwHPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_validators():\n",
        "  NN = MLPClassifier(max_iter = 1000)\n",
        "  LR = LogisticRegression(max_iter = 1000)\n",
        "  SVM = SVC()\n",
        "  ABC = AdaBoostClassifier()\n",
        "  GBC = GradientBoostingClassifier()\n",
        "  KNN = KNeighborsClassifier()\n",
        "  GNB = GaussianNB()\n",
        "  ET = ExtraTreesClassifier()\n",
        "  RF = RandomForestClassifier()\n",
        "  DT = DecisionTreeClassifier()\n",
        "  XGB = XGBClassifier()\n",
        "\n",
        "  return ([     'Neural Network',\n",
        "                'Logistic Regression',\n",
        "                'Support Vector Machine',\n",
        "                'Ada Boost Classifier',\n",
        "                'Gradient Boosting Classifier',\n",
        "                'K-Nearest Neighbors',\n",
        "               'Gaussian Naive Bayes',\n",
        "               'Extra Trees',\n",
        "               'Random Forest',\n",
        "               'Decision Tree',\n",
        "               'XGB Classifier'],\n",
        "          [NN, LR, SVM, ABC, GBC, KNN, GNB, ET, RF, DT, XGB])"
      ],
      "metadata": {
        "id": "OrcZEPZAwNwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names, models = get_validators()\n",
        "scores = get_score(names, models, xtrain_, ytrain_, xtest_, ytest_, 'Churn_Accu')\n",
        "\n",
        "scores"
      ],
      "metadata": {
        "id": "LdJHWDzCwRus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Another Experimentation Using Standard Scaler and using Cross Validation**"
      ],
      "metadata": {
        "id": "9NUysGQFwevl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from collections import Counter\n",
        "\n",
        "x = df_copy.drop(columns=['leave_STAY'])\n",
        "y = df_copy.leave_STAY\n",
        "\n",
        "# define oversampling strategy\n",
        "smote = SMOTE()\n",
        "smotex, smotey = smote.fit_resample(x, y)\n",
        "\n",
        "print(Counter(smotey))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "jrkwKQynwpZ2",
        "outputId": "ab8efcd1-a026-41ba-e94f-246ee69b4245"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_copy' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-ad2b7e5a7cc8>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'leave_STAY'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleave_STAY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_copy' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "for col in x:\n",
        "  smotex[col] = smotex[col].astype(float)\n",
        "  smotex[[col]] = scaler.fit_transform(smotex[[col]])\n",
        "\n",
        "smotex.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "BiOsx9ZBw6qQ",
        "outputId": "b575903b-b90b-486e-8ce1-29ec5d4a86b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'x' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-a99277e9547e>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0msmotex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmotex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0msmotex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmotex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split( smotex, smotey, test_size = 0.2 )\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import * #ExtraTreesClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.tree import *\n",
        "\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "NH-Ax4pHxA1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_validate(names, models, _X_train, _y_train, index, cv=10):\n",
        "  res = []\n",
        "  for model in models:\n",
        "    draft = model_selection.cross_val_score(model, _X_train, _y_train, cv=cv)\n",
        "    res.append(draft)\n",
        "  index = [index+' CV_' + str(i) for i in range(cv)]\n",
        "  accuracy = pd.DataFrame(np.array(res).T,\n",
        "                          columns=names,\n",
        "                          index=index,\n",
        "                          ).round(decimals=3)\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "GMB_GlcDxKcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_names, models = get_validators()\n",
        "accuracy = cross_validate(model_names, models, xtrain, ytrain, 'Churn_CV')\n",
        "accuracy"
      ],
      "metadata": {
        "id": "vTPDeE-ZxOo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'Model': ['Neural Network', 'Logistic Regression', 'Support Vector Machine', 'Ada Boost Classifier',\n",
        "              'Gradient Boosting Classifier', 'K-Nearest Neighbors', 'Gaussian Naive Bayes',\n",
        "              'Extra Trees', 'Random Forest', 'Decision Tree', 'XGB Classifier'],\n",
        "    'Churn_CV CV_0': [0.64, 0.63, 0.66, 0.66, 0.70, 0.62, 0.62, 0.67, 0.69, 0.61, 0.69],\n",
        "    'Churn_CV CV_1': [0.65, 0.65, 0.67, 0.67, 0.68, 0.63, 0.66, 0.68, 0.67, 0.62, 0.66],\n",
        "    'Churn_CV CV_2': [0.64, 0.63, 0.68, 0.67, 0.71, 0.60, 0.61, 0.67, 0.69, 0.63, 0.67],\n",
        "    'Churn_CV CV_3': [0.66, 0.65, 0.67, 0.67, 0.71, 0.61, 0.64, 0.67, 0.70, 0.62, 0.68],\n",
        "    'Churn_CV CV_4': [0.66, 0.65, 0.68, 0.67, 0.71, 0.63, 0.63, 0.68, 0.69, 0.64, 0.69],\n",
        "    'Churn_CV CV_5': [0.68, 0.64, 0.69, 0.67, 0.72, 0.62, 0.62, 0.70, 0.70, 0.63, 0.70],\n",
        "    'Churn_CV CV_6': [0.65, 0.63, 0.66, 0.65, 0.70, 0.61, 0.61, 0.67, 0.69, 0.62, 0.67],\n",
        "    'Churn_CV CV_7': [0.66, 0.64, 0.67, 0.67, 0.70, 0.61, 0.64, 0.69, 0.69, 0.61, 0.69],\n",
        "    'Churn_CV CV_8': [0.65, 0.63, 0.68, 0.66, 0.72, 0.63, 0.62, 0.69, 0.70, 0.63, 0.70],\n",
        "    'Churn_CV CV_9': [0.66, 0.65, 0.68, 0.66, 0.69, 0.63, 0.63, 0.69, 0.69, 0.60, 0.69]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Melt the dataframe to make it suitable for heatmap\n",
        "melted_df = df.melt(id_vars='Model', var_name='Fold', value_name='Accuracy')\n",
        "\n",
        "# Plotting the heatmap\n",
        "plt.figure(figsize=(12, 8))\n",
        "heatmap = sns.heatmap(melted_df.pivot(\"Model\", \"Fold\", \"Accuracy\"), annot=True, cmap=\"YlGnBu\")\n",
        "plt.title('Accuracy Heatmap Across Folds for Each Model')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fH_OaWpM1LyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data\n",
        "models = ['Neural Network', 'Logistic Regression', 'Support Vector Machine', 'Ada Boost Classifier',\n",
        "          'Gradient Boosting Classifier', 'K-Nearest Neighbors', 'Gaussian Naive Bayes',\n",
        "          'Extra Trees', 'Random Forest', 'Decision Tree', 'XGB Classifier']\n",
        "\n",
        "accuracy_data = [\n",
        "    [0.64, 0.65, 0.64, 0.66, 0.66, 0.68, 0.65, 0.66, 0.65, 0.66],\n",
        "    [0.63, 0.65, 0.63, 0.65, 0.65, 0.64, 0.63, 0.64, 0.63, 0.65],\n",
        "    [0.66, 0.67, 0.68, 0.67, 0.68, 0.69, 0.66, 0.67, 0.68, 0.68],\n",
        "    [0.66, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.67, 0.66, 0.66],\n",
        "    [0.70, 0.68, 0.71, 0.71, 0.71, 0.72, 0.70, 0.70, 0.72, 0.69],\n",
        "    [0.62, 0.63, 0.60, 0.61, 0.63, 0.62, 0.61, 0.63, 0.63, 0.63],\n",
        "    [0.62, 0.66, 0.61, 0.64, 0.63, 0.62, 0.61, 0.64, 0.63, 0.63],\n",
        "    [0.67, 0.68, 0.67, 0.67, 0.68, 0.70, 0.67, 0.69, 0.69, 0.69],\n",
        "    [0.69, 0.67, 0.69, 0.70, 0.69, 0.70, 0.69, 0.69, 0.70, 0.69],\n",
        "    [0.61, 0.62, 0.63, 0.62, 0.64, 0.63, 0.62, 0.61, 0.63, 0.60],\n",
        "    [0.69, 0.66, 0.67, 0.68, 0.69, 0.70, 0.67, 0.69, 0.70, 0.69]\n",
        "]\n",
        "\n",
        "# Calculate mean accuracy for each model\n",
        "mean_accuracy = np.mean(accuracy_data, axis=1)\n",
        "\n",
        "# Identify the model with the highest mean accuracy\n",
        "best_model_index = np.argmax(mean_accuracy)\n",
        "best_model = models[best_model_index]\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(12, 6))\n",
        "bars = plt.bar(models, mean_accuracy, color=['skyblue' if model != best_model else 'orange' for model in models])\n",
        "plt.title('Mean Accuracy Across Models')\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Mean Accuracy')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XEh1cAel3LNZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}